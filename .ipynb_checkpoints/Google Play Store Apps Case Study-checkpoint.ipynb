{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Case Study on Google Play Store Application Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELA CRUZ, Alexis Louis L. <br>\n",
    "NILL, Byron Ethelbert V. <br>\n",
    "UY, Geosef Viktor C.** <br>\n",
    "\n",
    "**28 September 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case study’s foundation is a dataset filled with information on applications from the Google Play Store and its objectives are geared towards answering questions in relation to an applications user rating. The first question of this case study deals with characteristics of mobile applications that may have an effect on its user rating such as, but not limited to, size, genre, and price. The second question may be considered a continuation of the first as it seeks to actually “assign” a rating to an unrated application based on similar programs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import **numpy**, **pandas**, **matplotlib**, **time**, **LinearRegression**, **LabelEncoder**, and **CollaborativeFiltering**, and **RuleMiner**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collaborative_filtering import CollaborativeFiltering\n",
    "from rule_miner import RuleMiner\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Play Store Dataset\n",
    "For this case study, the dataset chosen by the researchers is called `Google Play Store Apps` dataset. This dataset contains 10841 rows which represents transactions by customers shopping for groceries. The dataset contains 13 unique columns.\n",
    "\n",
    "The dataset is provided as `googleplaystore.csv`. Therefore, we must read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df = pd.read_csv('googleplaystore.csv')\n",
    "apps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data cleaning in this dataset, the researchers decided with these modifications.\n",
    "1. Remove `Last Updated`, `Current Ver`, `Android Ver`\n",
    "2. Include Main `Genres` Only\n",
    "3. Include Main `Content Rating` Only\n",
    "4. Numerical data for `Installs`, `Size`, `Price`\n",
    "5. Binning `Rating`, `Reviews`, `Size`, `Installs`\n",
    "6. Remove/Modify NaN and duplicate observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing `Last Updated`, `Current Ver`, `Android Ver`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case study, the columns `Last Updated`, `Current Ver`, and `Android Ver` are not needed and will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df = apps_df.drop([\"Last Updated\", \"Current Ver\", \"Android Ver\"], axis=1)\n",
    "apps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including Main Genre Only in `Genres`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The researchers noticed the presence of too much unique values for `Genres` due to a lot of apps having combined genres. The unique values can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Genres'].nunique(), apps_df['Genres'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, the researches decided to include only the main genres provided in `Genres`. This is to divide the apps into simpler genres and allow easier visualization of categories for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first genre which comes before the character `;` for multi-genre apps will be considered the main genre. Genres that come after will be removed via string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Genres\"] = apps_df[\"Genres\"].str.split(\";\", 1).str[0]\n",
    "apps_df[\"Genres\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that the `Genres` section contained a bizarre genre of 'February 11, 2018', so the researchers decided to see the values of these apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[apps_df[\"Genres\"] == \"February 11, 2018\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The researchers have chosen to drop this since it only contains one observation in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df = apps_df[apps_df['Genres'] != \"February 11, 2018\"]\n",
    "apps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including Main `Content Rating` Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen below that the `Content Rating` values contained some with 'Everyone' and 'Everyone 10+'. The researchers decided to exclude the age rating and only include the main content rating as well. In this case, the ratings would be 'Everyone', 'Teen', 'Mature', 'Adults', and 'Unrated'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Content Rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply splitting the strings by the whitespaces and including the first substring will divide the content ratings into its desirable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Content Rating\"] = apps_df[\"Content Rating\"].str.split(\" \", 1).str[0]\n",
    "apps_df[\"Content Rating\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Numerical Data for `Installs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `Installs` column below, it can be noticed that the data type for the values are not yet initialized as float. Therefore, the researchers will also use string manipulation for this column for conversion to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Installs\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, remove the '+' and ',' symbols to allow it for conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Installs'] = apps_df['Installs'].str.replace(\"+\", \"\")\n",
    "apps_df['Installs'] = apps_df['Installs'].str.replace(\",\", \"\")\n",
    "apps_df['Installs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it is possible to convert them into float using the pandas `to_numeric()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Installs'] = pd.to_numeric(apps_df['Installs'], downcast=\"float\")\n",
    "apps_df['Installs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Numerical Data for `Size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can be said for the `Size` column below. Therefore, the researchers will also use string manipulation for this column for conversion to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By replacing 'k' into 'e+3' and 'M' into 'e+6', it converts the values into a string that makes the `to_numeric()` function possible. However it is noticed that there is a value named 'Varies with device'. The researchers decided to convert that into NaN and deal with the NaN values in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Size\"] = apps_df[\"Size\"].str.replace('k', 'e+3')\n",
    "apps_df[\"Size\"] = apps_df[\"Size\"].str.replace('M', 'e+6')\n",
    "apps_df[\"Size\"] = apps_df[\"Size\"].replace('Varies with device', np.nan)\n",
    "apps_df[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, implementing the function will now be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Size\"] = pd.to_numeric(apps_df[\"Size\"], downcast=\"float\")\n",
    "apps_df[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Numerical Data for `Price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can also be said for the `Size` column below. Therefore, the researchers will also use string manipulation for this column for conversion to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Price'] = apps_df['Price'].str.replace(\"$\", \"\")\n",
    "apps_df[\"Price\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, using the `to_numeric()` function will now be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Price'] = pd.to_numeric(apps_df[\"Price\"], downcast=\"float\")\n",
    "apps_df['Price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicate and NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For duplicated rows, the researchers decided to simply drop these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df = apps_df.drop_duplicates()\n",
    "apps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preprocessing, the researchers decided to assign the `Rating` column before handling it to answer a specific question in the case study. It is only used to find NaN values for the test case in that question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_ratings = apps_df[['App', 'Rating']].copy()\n",
    "collab_ratings = collab_ratings.reset_index(drop=True)\n",
    "collab_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the null values below, the `Rating` and `Size` column will undergo preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Rating` and `Size`, the researchers used the average of the apps per `Genres`. The researchers decided to use this column instead of `Category` because the latter has fewer unique values than the other, making the former more specific to the apps' capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df.groupby(\"Genres\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the means for `Rating` and `Size` to be appropriate, an `apply()` function was done along with a lambda function that aims to assign the NaN values with the mean of those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Rating'] = apps_df.groupby(['Genres'], sort=False)['Rating'].apply(lambda x: x.fillna(x.mean()))\n",
    "apps_df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Size'] = apps_df.groupby(['Genres'], sort=False)['Size'].apply(lambda x: x.fillna(x.mean()))\n",
    "apps_df['Size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Impossible Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[apps_df[\"Installs\"] < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the minimized dataframe above, there are applications in the dataset that have zero `Installs` and zero `Reviews` but have a significant rating. These ratings usually come from users of applications but considering that there are no reviews and no installs for the applications above, it can be concluded that these rating values are untruthful or are either initial ratings from the developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(apps_df[apps_df[\"Installs\"] < 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the number of entries with this condition is less than 1% of the original dataset, we can drop these rows before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps_df = apps_df[apps_df[\"Installs\"] >= 1]\n",
    "apps_df[apps_df[\"Installs\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning `Rating`, `Reviews`, `Size`, `Install` into Appropriate Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of `Rating`, the researchers needed a new column that divides the rating into categories, which will be mainly used for association rules. The new column will then be called `Binned Rating`. For this binning process. the researches decided to use the `cut()` function since it is better to divide it into bins separating the ratings based on the actual value itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[apps_df[\"Rating\"] < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bins were finalized as 0-1, 1-2, 2-3, 3-4, and 4-5 inclusive. It is applicable since there is no rating that is below 1, above 5, nor is there an actual rating of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `Binned Rating` column is then integrated into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Binned Rating\"] = pd.cut(apps_df['Rating'], bins, labels=['Rating(0,1]', 'Rating(1,2]', 'Rating(2,3]', 'Rating(3,4]', 'Rating(4,5]' ])\n",
    "apps_df[\"Binned Rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for `Reviews`, `Installs` and `Size`, the researchers decided that it was appropriate to divide the reviews into quantiles so that the binning process can be more normalized in concern with the dataset present. They will be named `Binned Reviews`, `Binned Installs`, and `Binned Size` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The researchers chose 5 as the number of quantiles to divide them accordingly into 5 categories: very small, small, average, large, and very large. `Reviews` will be converted to float also in case of statistical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df[\"Reviews\"] = pd.to_numeric(apps_df[\"Reviews\"], downcast='float')\n",
    "apps_df['Binned Reviews'] = pd.qcut(apps_df['Reviews'], 5, labels=['Reviews(very small)', 'Reviews(small)', 'Reviews(average)', 'Reviews(large)', 'Reviews(very large)'])\n",
    "apps_df['Binned Reviews'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Binned Size'] = pd.qcut(apps_df['Size'], 5, labels=['Size(very small)', 'Size(small)', 'Size(average)', 'Size(large)', 'Size(very large)'])\n",
    "apps_df['Binned Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_df['Binned Installs'] = pd.qcut(apps_df['Installs'], 5, labels=['Installs(very small)', 'Installs(small)', 'Installs(average)', 'Installs(large)', 'Installs(very large)'])\n",
    "apps_df['Binned Installs'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is/are the variables that can mostly affect the rating of an app?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this research question, the proponents attempted to answer three specific questions that can base off of the general question:\n",
    "- Are ratings affected by application pricing?\n",
    "- What characteristics of a paid app can help in improving the rating of an app?\n",
    "- Are ratings relevant in user interest (no. of installs) of an app?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are ratings affected by application pricing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question aims to find a significant difference in rating when an app can be either `Free` or `Paid`. Therefore, it is possible to use hypothesis testing to find out the result of the significance. To determine this specific question, the categorized data is appropriate for the usage of chi-square. The test will use `Binned Rating` and `Type` as the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test, the hypotheses will be as follows:\n",
    "\n",
    "$H_0$ (null hypothesis): The true difference is 0. There is NO significant difference in the two categories.\n",
    "\n",
    "$H_A$ (alternative hypothesis): The true difference is not 0. There IS a significant difference in the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we group the apps' ratings according to their `Type`, and find the count for each rating category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = apps_df.groupby(\"Type\")[\"Binned Rating\"].value_counts()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data will be converted to a table to make it suitable for chi-square testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame([rating_counts[\"Free\"], rating_counts[\"Paid\"]], index=[\"Free\", \"Paid\"]).transpose()\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, implement the chi-square test onto the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it has a p-value of $ 4.5x 10^{-4} $, we reject the null hypothesis, meaning that there IS a significant difference in `Free` and `Paid` category apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it can be definitely seen that this is not enough to determine the difference in ratings of `Free` and `Paid` apps. In the expected value for the null hypothesis, see that the paid apps are all less than the free apps in all of the values. This is not due to the lack of paid apps present in the dataset, but the other way around. This is due to the sheer amount of free apps that are available in the Google Play Store. To further improve this result, possible recommendations include reducing the scope into genres, and addition of more paid apps to balance the count between `Free` and `Paid` apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What characteristics of a paid app can help in improving the rating of an app?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the first subquestion determined that the pricing of an app does hold a significance in the rating, the researchers decided to use it as a characteristic as well for the implementation of the question, as it seemed to have better insight on what seems to be the common features for an app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get association rules, we will follow the market-basket model. In this case study, a basket is represented as a mobile app (rows). The items or itemsets in the basket are represented by the characteristics of the mobile app. However, each characteristic of a mobile app belongs to a certain category. To implement the `Rule Miner` class, the dataset should only contain boolean values (0s and 1s) which denote if the basket model contains a certain item. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will be converted so that the columns are the unique values instead of the categories. All unique values except from the `App` columns are taken to build the `items` for the market-basket model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the `Price` column will be excluded alone for Association Rules. Instead of binning numerical values of price, it is much simpler to use the `Type` column which describes if the app is `Paid` or `Free`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataset now has binned columns, the original columns must also be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy_df = apps_df.copy()\n",
    "\n",
    "del copy_df['Rating']\n",
    "del copy_df['Reviews']\n",
    "del copy_df['Size']\n",
    "del copy_df['Price']\n",
    "del copy_df['Installs']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items = np.ndarray(shape=(1), dtype=object)\n",
    "\n",
    "for i in range(1, len(apps_df.columns)):\n",
    "    items = np.concatenate( (items, apps_df[apps_df.columns[i]].unique()), axis=0)\n",
    "\n",
    "items = np.delete(items, [0])\n",
    "\n",
    "for i in range(len(items)):\n",
    "    print(items[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique items will now be the columns for the dataframe. The dataframe is now a matrix that can represent the market basket model and is compatible with RuleMiner Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_df = pd.DataFrame(0, index=np.arange(len(apps_df.index)), columns=items)\n",
    "assoc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = copy_df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the market-basket model matrix, we now change the value of cells from `0` to `1` if the an application has that characteristic. This could take some time due to the very large size of the dataframe, but this code only needs to be executed once. For reference, it takes around 11 seconds to complete on an 7th gen i7 laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(assoc_df.index)):\n",
    "    for j in range(1, len(columns)):\n",
    "        assoc_df.loc[assoc_df.index[i], copy_df.loc[copy_df.index[i], columns[j]]] = 1\n",
    "        \n",
    "print (\"The program took \", time.time() - start_time, \" to run\")\n",
    "\n",
    "assoc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Rule Miner will also take a lot of time as we lower the thresholds. \n",
    "\n",
    "For reference (i7 7th gen laptop):\n",
    "- RuleMiner(300, 0.5) took 25 seconds to run\n",
    "- RuleMiner(100, 0.5) took 100 seconds to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first trial, let us try support thresholds 300 and confidence threshold 50%. There is no particular reason, this is something that can be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_miner = RuleMiner(300, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start1_time = time.time()\n",
    "\n",
    "rules = rule_miner.get_association_rules(assoc_df)\n",
    "#print(rules)\n",
    "# if you print this, it will look very ugly and may take up a lot of the screen\n",
    "\n",
    "print (\"The program took \", time.time() - start1_time, \" to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(rules), 2):\n",
    "    print(rules[i], \" -> \", rules[i+1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we want to see association rules (`x` -> `y`) such that `y` is a category for `Binned Ratings` to see what app characteristics are most likely to belong to a certain rating range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take the set of rating categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingset = copy_df['Binned Rating'].unique()\n",
    "ratingset = ratingset.tolist()\n",
    "ratingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(rules), 2):\n",
    "    x = rules[i]\n",
    "    y = rules[i+1]\n",
    "    if y[0] in ratingset:\n",
    "        print(rules[i], \" -> \", rules[i+1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Observations\n",
    "\n",
    "- 5 out of 5 rules have the `Free` characterstic which pertains to a free app\n",
    "- 4 out of 5 rules have the `Everyone` characteristic which pertains to an app that is suitable for all ages\n",
    "- 3 out of 5 rules have the `Installs(very large)` and `Reviews(very large)` characteristics which pertains to an app that has very large amount of reviews and installs relative to the distribution of data in the dataset'\n",
    "- The only `Category` characteristic among the 5 rules is `Game` which pertains to a game app.\n",
    "    - that rule is also the only rule among the 5 rules without `Everyone` as characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Characteristic such as `Installs (very large)` is a bit obvious because a highly rated app is very likely to be installed\n",
    "- Characteristic such as `Free` might also be caused by the large amount of free apps.\n",
    "- It might be worth to try less stricter threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_miner = RuleMiner(100, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1_time = time.time()\n",
    "\n",
    "rules = rule_miner.get_association_rules(assoc_df)\n",
    "#print(rules)\n",
    "# if you print this, it will look very ugly and may take up a lot of the screen\n",
    "\n",
    "print (\"The program took \", time.time() - start1_time, \" to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(rules), 2):\n",
    "    x = rules[i]\n",
    "    y = rules[i+1]\n",
    "    if y[0] in ratingset:\n",
    "        print(rules[i], \" -> \", rules[i+1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Observations\n",
    "\n",
    "- `Everyone` and `Free` are still dominant characteristics\n",
    "- Aside from `GAME`, there are also apps from `FAMILY`, `BUSINESS`, `PHOTOGRAPHY`, `MEDICAL`, and `TOOLS` category which are categories that may also correlate to high rating for apps\n",
    "- Out of 10 rules all having a `Review` and `Installs` characteristic, there are `5` very small and `5` very large\n",
    "     - All rules with `Review(very small)` have `Installs(very small)\n",
    "     - All rules with `Review(very large)` have `Installs(very large)\n",
    "- `GAME` category and `Action`genre are together in a rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis / Conclusion\n",
    "\n",
    "- There may be lot of apps with high rating due to having low number of installs and reviews\n",
    "    - This statement may likely to apply for `MEDICAL` and `BUSINESS` apps\n",
    "- For the `GAME` category, `Action` games are more likely to be highly rated and is likely to be not rated for `Everyone`\n",
    "- `PHOTOGRAPHY` apps are also likely to be rated high and is supported with high number of installs and reviews\n",
    "- `TOOLS` apps are also rated high and are supported with high number of installs and reviews however, there is still a good likeliness for it to have a high rating due to low number of installs and reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are ratings relevant in user interest (no. of installs) of an app?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third subquestion of this case study deals with the relationship of application rating and user interest. While ratings themselves may be considered measures of user interest, another field in this dataset may be considered as well: the number of installations an application has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the relationship between these variables, the researchers have decided to employ linear regression. The original dataframe will be reduced to two columns for ease in processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df = apps_df[['Rating', 'Installs']]\n",
    "linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the individual points will be plotted using `matplotlib`'s scatterplot function. A regression line will also be plotted with this scatterplot to see the relationship between the `Rating` and `Installs` variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the plot, the application `Rating` will be the independent variable on the x-axis and the number of `Installs` an application has will be the dependent variable on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = linreg_df.iloc[:, 0].values.reshape(-1, 1)\n",
    "y = linreg_df.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x, y)\n",
    "y_pred = linreg.predict(x)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, color='red')\n",
    "plt.title(\"Rating vs User Interest\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"User Interest\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above figure, there are large cavities with regard to the user interest (`Installs`) as compared to the `Rating` variable. This may be attributed to the existing values for the former variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_vals = linreg_df['Installs'].unique()\n",
    "install_vals.sort()\n",
    "install_vals.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset listed the values for `Installs` as strings of the form $x+$ where $x$ is any number from the above array. Upon execution of EDA and data cleaning, the values for this variable have been turned to floating-point numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, however, this left the values to be heavily varied with a standard deviation of *242403260* as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_vals.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reason why the scatterplot showed high variability with regard to the dependent values, specifically how the larger values (1 billion, 500 million, 100 million, 50 million) can easily be distinguished while the other values are cramped on the bottom of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove, or at least minimize, this variability, the researchers have decided to give random values within the correct range. \n",
    "\n",
    "For example, an application with an original `Installs` value of `500000+` and translated to a value of `500000.0` after EDA will be assigned a random value between 500000 and 1000000. This is in accordance with its original value of at least 500000 (`500000+`) but less than 1000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "def getInstallSampleVal (base):\n",
    "    if (base == 1000000000):\n",
    "        return 1000000000\n",
    "    \n",
    "    base_index = np.where(install_vals == base)[0][0]\n",
    "    min_val = install_vals[base_index]\n",
    "    max_val = install_vals[base_index + 1]\n",
    "    \n",
    "    return float(np.random.randint(min_val, max_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated values may be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vals = []\n",
    "\n",
    "for val in linreg_df['Installs']:\n",
    "    sample_vals.append(getInstallSampleVal(val))\n",
    "\n",
    "linreg_df['Installs_sample'] = sample_vals\n",
    "linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df['Installs_sample'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of the generated values is 107232458.6841. This may still be a larger than usual number but the variability of values has been decreased considering that the earlier standard deviation is more than 200 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process as before will be applied. The generated values will be plotted as the variable dependent on the original rating values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = linreg_df.iloc[:, 0].values.reshape(-1, 1)\n",
    "y_s = linreg_df.iloc[:, 2].values.reshape(-1, 1)\n",
    "\n",
    "linreg_s = LinearRegression()\n",
    "linreg_s.fit(x_s, y_s)\n",
    "y_s_pred = linreg_s.predict(x_s)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(x_s, y_s)\n",
    "plt.plot(x_s, y_s_pred, color='green', label=\"regression line\")\n",
    "plt.plot([1, 5], [100000000, 100000000], color=\"red\", label=\"y = 100 million\")\n",
    "plt.title(\"Rating vs User Interest\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"User Interest\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure above, the variability has somewhat decreased and the regression line is more akin to the data than before. However, considering the entire graph the overall variability is still evident considering that the $range$ of the dataset itself if (1000000000 - 1) or 999999999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applications with less than 100 million installs: \" +  str(len(linreg_df[linreg_df['Installs'] < 100000000])))\n",
    "print(\"Applications with at least 100 million installs: \" + str(len(linreg_df[linreg_df['Installs'] >= 100000000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression line, albeit more defined than before, can only be observed on the lower portion of the graph which may be due to the fact that a majority of the observations (n = 9861 / 10340) have `Installs` and, therefore, `Installs_sample` values of less than 100 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conlude this section, the researchers have decided to repeat the previous processes with minimized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_1_df = linreg_df[linreg_df['Installs'] < 100000000]\n",
    "linreg_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = linreg_1_df.iloc[:, 0].values.reshape(-1, 1)\n",
    "y_1 = linreg_1_df.iloc[:, 2].values.reshape(-1, 1)\n",
    "\n",
    "linreg_1 = LinearRegression()\n",
    "linreg_1.fit(x_1, y_1)\n",
    "y_1_pred = linreg_1.predict(x_1)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(x_1, y_1)\n",
    "plt.plot(x_1, y_1_pred, color='orange')\n",
    "plt.title(\"Rating vs User Interest (Installs < 100000000)\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"User Interest\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing the dataset to include only the majority of observations (`Installs` < 100000000) still yields a positive regression line (higher ratings yields higher installations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_100_df = linreg_df[linreg_df['Installs'] >= 100000000]\n",
    "linreg_100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_100 = linreg_100_df.iloc[:, 0].values.reshape(-1, 1)\n",
    "y_100 = linreg_100_df.iloc[:, 2].values.reshape(-1, 1)\n",
    "\n",
    "linreg_100 = LinearRegression()\n",
    "linreg_100.fit(x_100, y_100)\n",
    "y_100_pred = linreg_100.predict(x_100)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(x_100, y_100)\n",
    "plt.plot(x_100, y_100_pred, color='yellow')\n",
    "plt.title(\"Rating vs User Interest (Installs >= 100000000)\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"User Interest\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further minimizing the dataset to include only observations with `Installs` values of at least 100000000 results in the figure above. Contrary to the figure from before, a negative relationship may be observed from this figure as evidenced by the regression line above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the subquestion for this section, ratings are not significantly relevant in user interest. The contrasting relationships that have been shown in this section are evidences of this.\n",
    "\n",
    "While the scatterplots initially show that a higher rating will yield more installations for an application, the contrasting regression lines may prove otherwise. The `Rating vs User Interest (Installs < 100000000)` plot shows that a higher rating may indeed mean more installs for the application but the `Rating vs User Interest (Installs >= 100000000)` plot shows the reverse: higher ratings mean lower installation numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Is it possible to suggest the rating of an app given the variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, the researchers aimed to find the most similar items to an app with no rating given. That is why in this question, the `collab_ratings` variable will be used. However, compared to normal cosine similarity, the researchers decided to use it strictly on categorical data only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the dataframe suitable for cosine similarity, one-hot encoding will be implemented on the columns that are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific columns that are strictly categorical will be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_df = apps_df[['App', 'Category', 'Type', 'Content Rating', 'Genres', 'Binned Reviews', 'Binned Size', 'Binned Installs']]\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each category column is then transformed into numerical categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_df['Type']= le.fit_transform(collab_df['Type'])\n",
    "collab_df['Category']= le.fit_transform(collab_df['Category'])\n",
    "collab_df['Content Rating']= le.fit_transform(collab_df['Content Rating'])\n",
    "collab_df['Genres']= le.fit_transform(collab_df['Genres'])\n",
    "collab_df['Binned Reviews']= le.fit_transform(collab_df['Binned Reviews'])\n",
    "collab_df['Binned Size']= le.fit_transform(collab_df['Binned Size'])\n",
    "collab_df['Binned Installs']= le.fit_transform(collab_df['Binned Installs'])\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each category is then converted using one-hot encoding and assigned to their respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_category = pd.get_dummies(collab_df['Category'], prefix = 'category')\n",
    "one_hot_type = pd.get_dummies(collab_df['Type'], prefix = 'type')\n",
    "one_hot_content_rating = pd.get_dummies(collab_df['Content Rating'], prefix = 'content_rating')\n",
    "one_hot_genre = pd.get_dummies(collab_df['Genres'], prefix = 'genre')\n",
    "one_hot_review = pd.get_dummies(collab_df['Binned Reviews'], prefix = 'review')\n",
    "one_hot_size = pd.get_dummies(collab_df['Binned Size'], prefix = 'size')\n",
    "one_hot_install = pd.get_dummies(collab_df['Binned Installs'], prefix = 'install')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, concatenate the new columns and drop the previous columns, making the new dataframe a fully binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_df = collab_df.join([one_hot_category, one_hot_type, one_hot_content_rating, one_hot_genre, one_hot_review, one_hot_size, one_hot_install])\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_df = collab_df.drop(columns=['Category', 'Type', 'Content Rating', 'Genres', 'Binned Reviews', 'Binned Size', 'Binned Installs'])\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of the index into the app name itself makes it possible to use collaborative filtering functions in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_df = collab_df.set_index('App')\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, the researchers chose 500 apps that can be similar to the chosen app because that is what the researchers thought would be a good starting ground for the filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfilter = CollaborativeFiltering(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `collab_rating` column, it is possible to search for a NaN value inside this and use that as the test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that index 10337 does not contain a rating. Let us try and suggest a rating using that as a basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index = 10337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_df['index'] = range(0, len(collab_df))\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity, $S_c$, between two vectors $A$ and $B$ is computed as:\n",
    "$$S_c(A, B)=\\dfrac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let us use the first app as a basis, and use the `get_cosine_similarity()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sim, ind = cfilter.get_cosine_similarity(collab_df.iloc[0, :], collab_df.iloc[1:, :])\n",
    "print('Photo Editor & Candy Camera & Grid & ScrapBook:', [round(x, 2) for x in collab_df.iloc[0, :]])\n",
    "print('\\nCosine similarities:\\n' + str(sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to find the k similar apps using the `get_k_similar()` function. In this case, the k was instantiated to be 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main_app = collab_df.iloc[index, :]\n",
    "other_apps = collab_df.iloc[:index, :].append(collab_df.iloc[index+1:, :])\n",
    "similar_index, similar_apps = cfilter.get_k_similar(other_apps, main_app)\n",
    "print(similar_apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rating of user `x` to item `i`, represented as $r_{xi}$, given the set of similar items `N`, is computed as:\n",
    "\n",
    "$$r_{xi}=\\dfrac{\\sum_{y \\in N}^{}s_{xy}r_{yi}}{\\sum_{y \\in N}^{}s_{xy}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we reset the index of the similarities to clean the instance and assign it to `sum_sim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_sim = similar_apps[0]\n",
    "sum_sim = sum_sim.reset_index()[0]\n",
    "sum_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the rating for predicting the app is taken from `apps_df`. Note that the researchers did not take the ratings from `collab_ratings`, for it contained NaN values and it was determined to be inaccurate when using it. That is why the researchers decided to use the preprocessed data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_for_prediction = apps_df[['App', 'Rating']].reset_index(drop=True)\n",
    "rating_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the ratings, the index of, in this case, the 500 apps is taken from `similar_apps`, which will be the rating respective to the similarity in the specific rows. Resetting of index is also done to clean the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_sim = rating_for_prediction.iloc[similar_apps['index']]\n",
    "rating_sim = rating_sim['Rating'].reset_index(drop=True)\n",
    "rating_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the top cosine similarities of the apps and the ratings of those apps, the formula can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sum_sim * rating_sim).sum() / sum_sim.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(sum_sim * rating_sim).sum()` denotes $${\\sum_{y \\in N}^{}s_{xy}r_{yi}}$$ of the equation, and `sum_sim.sum()` denotes $${\\sum_{y \\in N}^{}s_{xy}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to suggest a rating using the dataset presented. Using cosine similarities of one-hot encoded data, predicting the rating of an app containing preprocessed data can be done. It is possible to continue this prediction to other ratings by **assigning the newly found rating** to its respective app, and **solve for the ratings of other preprocessed apps**. Repetition of these steps will yield the process closer and closer prediction of the rating after many iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case study is geared on determining the characteristics that affect a mobile application’s user satisfaction rating and “guess” the rating of an unrated application given these characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question was further divided into three subquestions each tackling a separate matter in relation to factors affecting the application rating. The first subquestion aimed to find differences between the ratings of paid and free applications and, upon completion of a chi-square statistical test, there was indeed a difference between the two. However, the researchers deemed the test to be lacking in integrity due to the fact that there is a large disparity between the number of free and the number of paid applications present in the dataset. The second subquestion was answered using the association rules data mining technique. Here, the researchers determined application characteristics that yielded rating values in the higher range of `(4, 5]`; a significant correlation may be found between a lower number of installations and reviews and a higher actual rating and rightfully so, as newer applications may have higher individual ratings or have rating entries that pull its overall rating to a higher value. Lastly, the third question dealt with the significance of application rating in the number of installations an application has. This was done through linear regression but it was found that the ratings do not matter significantly if a user installs a specific application as was found in contrasting regression analyses. This may also be viewed in an alternate sense such that the more installations an application gets, more and more users may give less-than-average reviews that pull its review down. In general, applications do have characteristics that affect their overall rating such as their installation and review quantities, genre, content rating, and pricing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second question was mainly answered through the implementation of collaborative filtering, and the usage of cosine similarity in categorical data. One-hot encoding was implemented to make it suitable for cosine similarity, and the similar apps were chosen. The ratings of these apps were taken into account and using its corresponding cosine similarities, a predicted rating is found as a result. Undergoing this process will provide the dataset with closer ratings once it is repeated with a significant number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give further depth to the study and give more accurate results, the researchers recommend the increase in the volume of paid apps in the dataset. Since the dataset contained mostly free apps, adding more details regarding paid apps will add more insight into this category, and give more accurate results when comparing them to free apps. Allowing manipulation of the support threshold and the confidence threshold may give new insights for the categories as it may introduce new association rules. Initially, the second subquestion aimed to determine what characteristics of a paid app can help in improving the rating of an app. However, the scope was changed to all apps in general instead of paid apps alone because it was determined that the pricing of an app does hold a significance in the rating. The researchers decided to consider free apps as well for the implementation of the question, as it seemed to provide a better insight on what seems to be the common features for an app. Furthermore, introducing the usage of either ordinal or logistic regression can provide a better understanding on the relevance of the variables. The usage of ordinal regression can provide better insight with the incorporation of ordered variables in the dataset, specifically the application rating, and logistic regression for the categorical variables. Lastly, the researchers recommend that collaborative filtering be executed differently such that the data to be used in suggesting a rating for an unrated application is not preprocessed. That is, rating suggestions must be based on the original ratings of similar applications and if, by any chance, these similar applications are also unrated, the next similar application to it will be used, in repetition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
